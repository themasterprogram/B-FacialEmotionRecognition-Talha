{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPKoexI0S1tAeuKYGl7S2mK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/themasterprogram/B-FacialEmotionRecognition-Talha/blob/main/FacialEmotionRecognition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "Whk-EbHSMAYR"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import cv2\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from keras.utils import plot_model\n",
        "from keras.models import Model\n",
        "\n",
        "from keras.regularizers import l1, l2\n",
        "from matplotlib import pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "from keras.layers import Input, Dense, Flatten, Dropout, BatchNormalization\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import concatenate\n",
        "from keras.optimizers import Adam, SGD\n",
        "from keras.regularizers import l1, l2\n",
        "from matplotlib import pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/Drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "alR2RSWyQgR4",
        "outputId": "6a917821-ec9d-44e8-f0fd-f9b8cbc3e30b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/Drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/Drive/MyDrive"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3pHQ_E4LRSe7",
        "outputId": "087cc2bc-d880-4df0-f897-e3b3322accb0"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Drive/MyDrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/Drive/MyDrive/fer/fer2013/fer2013"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J1MNW2riRc2v",
        "outputId": "596008ce-2263-4a8d-bf06-79a0ed3db90a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Drive/MyDrive/fer/fer2013/fer2013\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = []\n",
        "y_train = []\n",
        "X_test = []\n",
        "y_test = []\n",
        "df = pd.read_csv(\"fer2013.csv\")\n",
        "for index, row in df.iterrows():\n",
        "    k = row['pixels'].split(\" \")\n",
        "    if row['Usage'] == 'Training':\n",
        "        X_train.append(np.array(k))\n",
        "        y_train.append(row['emotion'])\n",
        "    elif row['Usage'] == 'PublicTest':\n",
        "        X_test.append(np.array(k))\n",
        "        y_test.append(row['emotion'])\n",
        "\n",
        "X_train = np.array(X_train, dtype = 'uint8')\n",
        "y_train = np.array(y_train, dtype = 'uint8')\n",
        "X_test = np.array(X_test, dtype = 'uint8')\n",
        "y_test = np.array(y_test, dtype = 'uint8')"
      ],
      "metadata": {
        "id": "8285tkzQMOCJ"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import keras\n",
        "from keras.utils import to_categorical\n",
        "y_train= to_categorical(y_train, num_classes=7)\n",
        "y_test = to_categorical(y_test, num_classes=7)"
      ],
      "metadata": {
        "id": "i05TWHIvSBjE"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = X_train.reshape(X_train.shape[0], 48, 48, 1)\n",
        "X_test = X_test.reshape(X_test.shape[0], 48, 48, 1)"
      ],
      "metadata": {
        "id": "F90pEIMJRqu4"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range = 10,\n",
        "    horizontal_flip = True,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    fill_mode = 'nearest')\n",
        "testgen = ImageDataGenerator(rescale=1./255)\n",
        "datagen.fit(X_train)\n",
        "batch_size = 64"
      ],
      "metadata": {
        "id": "MXg1PhIQjkXv"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_flow = datagen.flow(X_train, y_train, batch_size=batch_size)\n",
        "test_flow = testgen.flow(X_test, y_test, batch_size=batch_size)"
      ],
      "metadata": {
        "id": "DA6KmQ9UlAgD"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def FER_Model(input_shape=(48,48,1)):\n",
        "    # first input model\n",
        "    visible = Input(shape=input_shape, name='input')\n",
        "    num_classes = 7\n",
        "    #the 1-st block\n",
        "    conv1_1 = Conv2D(64, kernel_size=3, activation='relu', padding='same', name = 'conv1_1')(visible)\n",
        "    conv1_1 = BatchNormalization()(conv1_1)\n",
        "    conv1_2 = Conv2D(64, kernel_size=3, activation='relu', padding='same', name = 'conv1_2')(conv1_1)\n",
        "    conv1_2 = BatchNormalization()(conv1_2)\n",
        "    pool1_1 = MaxPooling2D(pool_size=(2,2), name = 'pool1_1')(conv1_2)\n",
        "    drop1_1 = Dropout(0.3, name = 'drop1_1')(pool1_1)#the 2-nd block\n",
        "    conv2_1 = Conv2D(128, kernel_size=3, activation='relu', padding='same', name = 'conv2_1')(drop1_1)\n",
        "    conv2_1 = BatchNormalization()(conv2_1)\n",
        "    conv2_2 = Conv2D(128, kernel_size=3, activation='relu', padding='same', name = 'conv2_2')(conv2_1)\n",
        "    conv2_2 = BatchNormalization()(conv2_2)\n",
        "    conv2_3 = Conv2D(128, kernel_size=3, activation='relu', padding='same', name = 'conv2_3')(conv2_2)\n",
        "    conv2_2 = BatchNormalization()(conv2_3)\n",
        "    pool2_1 = MaxPooling2D(pool_size=(2,2), name = 'pool2_1')(conv2_3)\n",
        "    drop2_1 = Dropout(0.3, name = 'drop2_1')(pool2_1)#the 3-rd block\n",
        "    conv3_1 = Conv2D(256, kernel_size=3, activation='relu', padding='same', name = 'conv3_1')(drop2_1)\n",
        "    conv3_1 = BatchNormalization()(conv3_1)\n",
        "    conv3_2 = Conv2D(256, kernel_size=3, activation='relu', padding='same', name = 'conv3_2')(conv3_1)\n",
        "    conv3_2 = BatchNormalization()(conv3_2)\n",
        "    conv3_3 = Conv2D(256, kernel_size=3, activation='relu', padding='same', name = 'conv3_3')(conv3_2)\n",
        "    conv3_3 = BatchNormalization()(conv3_3)\n",
        "    conv3_4 = Conv2D(256, kernel_size=3, activation='relu', padding='same', name = 'conv3_4')(conv3_3)\n",
        "    conv3_4 = BatchNormalization()(conv3_4)\n",
        "    pool3_1 = MaxPooling2D(pool_size=(2,2), name = 'pool3_1')(conv3_4)\n",
        "    drop3_1 = Dropout(0.3, name = 'drop3_1')(pool3_1)#the 4-th block\n",
        "    conv4_1 = Conv2D(256, kernel_size=3, activation='relu', padding='same', name = 'conv4_1')(drop3_1)\n",
        "    conv4_1 = BatchNormalization()(conv4_1)\n",
        "    conv4_2 = Conv2D(256, kernel_size=3, activation='relu', padding='same', name = 'conv4_2')(conv4_1)\n",
        "    conv4_2 = BatchNormalization()(conv4_2)\n",
        "    conv4_3 = Conv2D(256, kernel_size=3, activation='relu', padding='same', name = 'conv4_3')(conv4_2)\n",
        "    conv4_3 = BatchNormalization()(conv4_3)\n",
        "    conv4_4 = Conv2D(256, kernel_size=3, activation='relu', padding='same', name = 'conv4_4')(conv4_3)\n",
        "    conv4_4 = BatchNormalization()(conv4_4)\n",
        "    pool4_1 = MaxPooling2D(pool_size=(2,2), name = 'pool4_1')(conv4_4)\n",
        "    drop4_1 = Dropout(0.3, name = 'drop4_1')(pool4_1)\n",
        "\n",
        "    #the 5-th block\n",
        "    conv5_1 = Conv2D(512, kernel_size=3, activation='relu', padding='same', name = 'conv5_1')(drop4_1)\n",
        "    conv5_1 = BatchNormalization()(conv5_1)\n",
        "    conv5_2 = Conv2D(512, kernel_size=3, activation='relu', padding='same', name = 'conv5_2')(conv5_1)\n",
        "    conv5_2 = BatchNormalization()(conv5_2)\n",
        "    conv5_3 = Conv2D(512, kernel_size=3, activation='relu', padding='same', name = 'conv5_3')(conv5_2)\n",
        "    conv5_3 = BatchNormalization()(conv5_3)\n",
        "    conv5_4 = Conv2D(512, kernel_size=3, activation='relu', padding='same', name = 'conv5_4')(conv5_3)\n",
        "    conv5_4 = BatchNormalization()(conv5_3)\n",
        "    pool5_1 = MaxPooling2D(pool_size=(2,2), name = 'pool5_1')(conv5_4)\n",
        "    drop5_1 = Dropout(0.3, name = 'drop5_1')(pool5_1)#Flatten and output\n",
        "    flatten = Flatten(name = 'flatten')(drop5_1)\n",
        "    ouput = Dense(num_classes, activation='softmax', name = 'output')(flatten)# create model\n",
        "    model = Model(inputs =visible, outputs = ouput)\n",
        "    # summary layers\n",
        "    print(model.summary())\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "yCdEfF0tlXvq"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = FER_Model()\n",
        "opt = tf.keras.optimizers.legacy.Adam(learning_rate=0.0001, decay=1e-6)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sIM9Nb0Zl2S8",
        "outputId": "c6395e8c-2c5c-47cb-9d5e-9552bb465ad2"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_4\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input (InputLayer)          [(None, 48, 48, 1)]       0         \n",
            "                                                                 \n",
            " conv1_1 (Conv2D)            (None, 48, 48, 64)        640       \n",
            "                                                                 \n",
            " batch_normalization_68 (Ba  (None, 48, 48, 64)        256       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv1_2 (Conv2D)            (None, 48, 48, 64)        36928     \n",
            "                                                                 \n",
            " batch_normalization_69 (Ba  (None, 48, 48, 64)        256       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " pool1_1 (MaxPooling2D)      (None, 24, 24, 64)        0         \n",
            "                                                                 \n",
            " drop1_1 (Dropout)           (None, 24, 24, 64)        0         \n",
            "                                                                 \n",
            " conv2_1 (Conv2D)            (None, 24, 24, 128)       73856     \n",
            "                                                                 \n",
            " batch_normalization_70 (Ba  (None, 24, 24, 128)       512       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2_2 (Conv2D)            (None, 24, 24, 128)       147584    \n",
            "                                                                 \n",
            " batch_normalization_71 (Ba  (None, 24, 24, 128)       512       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2_3 (Conv2D)            (None, 24, 24, 128)       147584    \n",
            "                                                                 \n",
            " pool2_1 (MaxPooling2D)      (None, 12, 12, 128)       0         \n",
            "                                                                 \n",
            " drop2_1 (Dropout)           (None, 12, 12, 128)       0         \n",
            "                                                                 \n",
            " conv3_1 (Conv2D)            (None, 12, 12, 256)       295168    \n",
            "                                                                 \n",
            " batch_normalization_73 (Ba  (None, 12, 12, 256)       1024      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv3_2 (Conv2D)            (None, 12, 12, 256)       590080    \n",
            "                                                                 \n",
            " batch_normalization_74 (Ba  (None, 12, 12, 256)       1024      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv3_3 (Conv2D)            (None, 12, 12, 256)       590080    \n",
            "                                                                 \n",
            " batch_normalization_75 (Ba  (None, 12, 12, 256)       1024      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv3_4 (Conv2D)            (None, 12, 12, 256)       590080    \n",
            "                                                                 \n",
            " batch_normalization_76 (Ba  (None, 12, 12, 256)       1024      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " pool3_1 (MaxPooling2D)      (None, 6, 6, 256)         0         \n",
            "                                                                 \n",
            " drop3_1 (Dropout)           (None, 6, 6, 256)         0         \n",
            "                                                                 \n",
            " conv4_1 (Conv2D)            (None, 6, 6, 256)         590080    \n",
            "                                                                 \n",
            " batch_normalization_77 (Ba  (None, 6, 6, 256)         1024      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv4_2 (Conv2D)            (None, 6, 6, 256)         590080    \n",
            "                                                                 \n",
            " batch_normalization_78 (Ba  (None, 6, 6, 256)         1024      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv4_3 (Conv2D)            (None, 6, 6, 256)         590080    \n",
            "                                                                 \n",
            " batch_normalization_79 (Ba  (None, 6, 6, 256)         1024      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv4_4 (Conv2D)            (None, 6, 6, 256)         590080    \n",
            "                                                                 \n",
            " batch_normalization_80 (Ba  (None, 6, 6, 256)         1024      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " pool4_1 (MaxPooling2D)      (None, 3, 3, 256)         0         \n",
            "                                                                 \n",
            " drop4_1 (Dropout)           (None, 3, 3, 256)         0         \n",
            "                                                                 \n",
            " conv5_1 (Conv2D)            (None, 3, 3, 512)         1180160   \n",
            "                                                                 \n",
            " batch_normalization_81 (Ba  (None, 3, 3, 512)         2048      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv5_2 (Conv2D)            (None, 3, 3, 512)         2359808   \n",
            "                                                                 \n",
            " batch_normalization_82 (Ba  (None, 3, 3, 512)         2048      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv5_3 (Conv2D)            (None, 3, 3, 512)         2359808   \n",
            "                                                                 \n",
            " batch_normalization_83 (Ba  (None, 3, 3, 512)         2048      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " batch_normalization_84 (Ba  (None, 3, 3, 512)         2048      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " pool5_1 (MaxPooling2D)      (None, 1, 1, 512)         0         \n",
            "                                                                 \n",
            " drop5_1 (Dropout)           (None, 1, 1, 512)         0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 512)               0         \n",
            "                                                                 \n",
            " output (Dense)              (None, 7)                 3591      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 10753607 (41.02 MB)\n",
            "Trainable params: 10744647 (40.99 MB)\n",
            "Non-trainable params: 8960 (35.00 KB)\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 100\n",
        "history = model.fit_generator(train_flow,\n",
        "                    steps_per_epoch=len(X_train) / batch_size,\n",
        "                    epochs=num_epochs,\n",
        "                    verbose=1,\n",
        "                    validation_data=test_flow,\n",
        "                    validation_steps=len(X_test) / batch_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nZ9QTm5dmwhZ",
        "outputId": "73d7a9c5-0785-409e-b397-7c08ccdd8e7c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-26-c57d8e88c2d2>:2: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  history = model.fit_generator(train_flow,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "  6/448 [..............................] - ETA: 1:20:52 - loss: 3.6441 - accuracy: 0.1797"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_json = model.to_json()\n",
        "with open(\"model.json\", \"w\") as json_file:\n",
        "    json_file.write(model_json)\n",
        "model.save_weights(\"model.h5\")\n",
        "print(\"Saved model to disk\")"
      ],
      "metadata": {
        "id": "wtw5sGh_ocNh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}