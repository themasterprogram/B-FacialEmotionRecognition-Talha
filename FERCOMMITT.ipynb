{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/themasterprogram/B-FacialEmotionRecognition-Talha/blob/main/FERCOMMITT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Whk-EbHSMAYR"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import cv2\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "from keras.utils import plot_model\n",
        "from keras.models import Model\n",
        "\n",
        "from keras.regularizers import l1, l2\n",
        "from matplotlib import pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "from keras.layers import Input, Dense, Flatten, Dropout, BatchNormalization\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import concatenate\n",
        "from keras.optimizers import Adam, SGD\n",
        "from keras.regularizers import l1, l2\n",
        "from matplotlib import pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "alR2RSWyQgR4",
        "outputId": "32747eba-6d2f-4c7b-b1a7-a1ac3f192490"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/Drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/Drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3pHQ_E4LRSe7",
        "outputId": "43a65184-1a97-4ebe-b872-569bb937236e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Drive/MyDrive\n"
          ]
        }
      ],
      "source": [
        "%cd /content/Drive/MyDrive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J1MNW2riRc2v",
        "outputId": "84e542f9-822e-49bd-979b-ef6bf7c737ec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/Drive/MyDrive/fer/fer2013/fer2013\n"
          ]
        }
      ],
      "source": [
        "%cd /content/Drive/MyDrive/fer/fer2013/fer2013"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "8285tkzQMOCJ"
      },
      "outputs": [],
      "source": [
        "X_train = []\n",
        "y_train = []\n",
        "X_test = []\n",
        "y_test = []\n",
        "df = pd.read_csv(\"fer2013.csv\")\n",
        "for index, row in df.iterrows():\n",
        "    k = row['pixels'].split(\" \")\n",
        "    if row['Usage'] == 'Training':\n",
        "        X_train.append(np.array(k))\n",
        "        y_train.append(row['emotion'])\n",
        "    elif row['Usage'] == 'PublicTest':\n",
        "        X_test.append(np.array(k))\n",
        "        y_test.append(row['emotion'])\n",
        "\n",
        "X_train = np.array(X_train, dtype = 'uint8')\n",
        "y_train = np.array(y_train, dtype = 'uint8')\n",
        "X_test = np.array(X_test, dtype = 'uint8')\n",
        "y_test = np.array(y_test, dtype = 'uint8')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "i05TWHIvSBjE"
      },
      "outputs": [],
      "source": [
        "import keras\n",
        "from keras.utils import to_categorical\n",
        "y_train= to_categorical(y_train, num_classes=7)\n",
        "y_test = to_categorical(y_test, num_classes=7)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "F90pEIMJRqu4"
      },
      "outputs": [],
      "source": [
        "X_train = X_train.reshape(X_train.shape[0], 48, 48, 1)\n",
        "X_test = X_test.reshape(X_test.shape[0], 48, 48, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "MXg1PhIQjkXv"
      },
      "outputs": [],
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range = 10,\n",
        "    horizontal_flip = True,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    fill_mode = 'nearest')\n",
        "testgen = ImageDataGenerator(rescale=1./255)\n",
        "datagen.fit(X_train)\n",
        "batch_size = 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "DA6KmQ9UlAgD"
      },
      "outputs": [],
      "source": [
        "train_flow = datagen.flow(X_train, y_train, batch_size=batch_size)\n",
        "test_flow = testgen.flow(X_test, y_test, batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "yCdEfF0tlXvq"
      },
      "outputs": [],
      "source": [
        "def FER_Model(input_shape=(48,48,1)):\n",
        "    # first input model\n",
        "    visible = Input(shape=input_shape, name='input')\n",
        "    num_classes = 7\n",
        "    #the 1-st block\n",
        "    conv1_1 = Conv2D(64, kernel_size=3, activation='relu', padding='valid', name = 'conv1_1')(visible)\n",
        "    #After 1st convolution the feature map is 46x46\n",
        "    conv1_1 = BatchNormalization()(conv1_1)\n",
        "    pool1_1 = MaxPooling2D(pool_size = (2,2), strides = 2, padding = 'valid')(conv1_1)\n",
        "    #After Max Pooling Layer the feature map becomes 23x23\n",
        "\n",
        "    #2nd Block:\n",
        "    conv2 = Conv2D(128, kernel_size = 3, activation = 'relu', padding = 'valid', name = 'conv2')(pool1_1)\n",
        "    #After this convolution layer feature map becomes 21x21\n",
        "    conv2 = BatchNormalization()(conv2)\n",
        "    pool2 = MaxPooling2D(pool_size = (2,2),strides = 1,padding = 'valid')(conv2)\n",
        "    #After this maxpooling layer feature map becomes 20x20\n",
        "\n",
        "    #3rd Block:\n",
        "    conv3 = Conv2D(256, kernel_size=3, activation='relu', padding='valid', name = 'conv3')(pool2)\n",
        "    #After this conv layer feature map becomes 18x18\n",
        "    conv3 = BatchNormalization()(conv3)\n",
        "    pool3 = MaxPooling2D(pool_size=(2,2),strides = 2, padding = 'valid')(conv3)\n",
        "    #After this pooling layer feature map becomes 9x9\n",
        "    drop1 = Dropout(0.3, name = 'drop1')(pool3)\n",
        "    #the 4th block\n",
        "    conv4 = Conv2D(512, kernel_size=3, activation='relu', padding='same', name = 'conv4')(drop1)\n",
        "    #After this conv layer feature map becomes 7x7\n",
        "    conv4 = BatchNormalization()(conv4)\n",
        "    pool4 = MaxPooling2D(pool_size = (2,2), strides = 1, padding = 'valid')(conv4)\n",
        "    #After this pooling layer feature map becomes 6x6\n",
        "    conv5 = Conv2D(1024, kernel_size=3, activation='relu', padding='same', name = 'conv5')(pool4)\n",
        "    #After this conv layer feature map becomes 4x4\n",
        "    conv5 = BatchNormalization()(conv5)\n",
        "    pool5 = MaxPooling2D(pool_size = (2,2), strides = 2, padding = 'valid')(conv5)\n",
        "    #After this pooling layer feature map becomes 2x2\n",
        "    drop2 = Dropout(0.3, name = 'drop2')(pool5)\n",
        "\n",
        "\n",
        "    flatten = Flatten(name = 'flatten')(drop2)\n",
        "    #I chose 2048 as number of neurons in this layer because of 2*1024, 2x2 was the size of the latest feature map, 1024 was the number of feature maps/filters\n",
        "    Dense1 = Dense(2048,activation = 'relu',name = 'Dense1' )(flatten)\n",
        "    Dense2 = Dense(1024, activation = 'relu', name = 'Dense2')(Dense1)\n",
        "    Dense3 = Dense(512, activation = 'relu', name = 'Dense3')(Dense2)\n",
        "    Dense4 = Dense(256, activation = 'relu', name = 'Dense4')(Dense3)\n",
        "    ouput = Dense(num_classes, activation='softmax', name = 'output')(Dense4)# create model\n",
        "    model = Model(inputs =visible, outputs = ouput)\n",
        "    # summary layers\n",
        "    print(model.summary())\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sIM9Nb0Zl2S8",
        "outputId": "53fec1ba-4c36-4aeb-e8be-a32c54d765a6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input (InputLayer)          [(None, 48, 48, 1)]       0         \n",
            "                                                                 \n",
            " conv1_1 (Conv2D)            (None, 46, 46, 64)        640       \n",
            "                                                                 \n",
            " batch_normalization_14 (Ba  (None, 46, 46, 64)        256       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling2d_12 (MaxPooli  (None, 23, 23, 64)        0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " conv2 (Conv2D)              (None, 21, 21, 128)       73856     \n",
            "                                                                 \n",
            " batch_normalization_15 (Ba  (None, 21, 21, 128)       512       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling2d_13 (MaxPooli  (None, 20, 20, 128)       0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " conv3 (Conv2D)              (None, 18, 18, 256)       295168    \n",
            "                                                                 \n",
            " batch_normalization_16 (Ba  (None, 18, 18, 256)       1024      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling2d_14 (MaxPooli  (None, 9, 9, 256)         0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " drop1 (Dropout)             (None, 9, 9, 256)         0         \n",
            "                                                                 \n",
            " conv4 (Conv2D)              (None, 9, 9, 512)         1180160   \n",
            "                                                                 \n",
            " batch_normalization_17 (Ba  (None, 9, 9, 512)         2048      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling2d_15 (MaxPooli  (None, 8, 8, 512)         0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " conv5 (Conv2D)              (None, 8, 8, 1024)        4719616   \n",
            "                                                                 \n",
            " batch_normalization_18 (Ba  (None, 8, 8, 1024)        4096      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling2d_16 (MaxPooli  (None, 4, 4, 1024)        0         \n",
            " ng2D)                                                           \n",
            "                                                                 \n",
            " drop2 (Dropout)             (None, 4, 4, 1024)        0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 16384)             0         \n",
            "                                                                 \n",
            " Dense1 (Dense)              (None, 2048)              33556480  \n",
            "                                                                 \n",
            " Dense2 (Dense)              (None, 1024)              2098176   \n",
            "                                                                 \n",
            " Dense3 (Dense)              (None, 512)               524800    \n",
            "                                                                 \n",
            " Dense4 (Dense)              (None, 256)               131328    \n",
            "                                                                 \n",
            " output (Dense)              (None, 7)                 1799      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 42589959 (162.47 MB)\n",
            "Trainable params: 42585991 (162.45 MB)\n",
            "Non-trainable params: 3968 (15.50 KB)\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "model = FER_Model()\n",
        "opt = tf.keras.optimizers.legacy.Adam(learning_rate=0.0001, decay=1e-6)\n",
        "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "nZ9QTm5dmwhZ",
        "outputId": "c1e2e9fd-0b52-42e0-8d4b-6bc618674b95"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-20-37e6bcd0ecfb>:2: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  history = model.fit_generator(train_flow,\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            " 35/448 [=>............................] - ETA: 43:48 - loss: 1.9934 - accuracy: 0.2375"
          ]
        }
      ],
      "source": [
        "num_epochs = 100\n",
        "history = model.fit_generator(train_flow,\n",
        "                    steps_per_epoch=len(X_train) / batch_size,\n",
        "                    epochs=num_epochs,\n",
        "                    verbose=1,\n",
        "                    validation_data=test_flow,\n",
        "                    validation_steps=len(X_test) / batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wtw5sGh_ocNh"
      },
      "outputs": [],
      "source": [
        "model_json = model.to_json()\n",
        "with open(\"model.json\", \"w\") as json_file:\n",
        "    json_file.write(model_json)\n",
        "model.save_weights(\"model.h5\")\n",
        "print(\"Saved model to disk\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO0RVUctTImmF6Ivvi38BGH",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}